---
title: "R Notebook for Climate Change Trends"
output: github_document
always_allow_html: true
---

Loading the libraries requied to analyze the datasets:

```{r}
#loading the required packages
library(tidyverse)
library(corrplot)
library(VIM)
library(Hmisc)
library(psych)
library(ggplot2)
library(dplyr)
library(plotly)
library(GGally)
library(mice)
library(readr)
library(patchwork)
library(ggcorrplot)
library(gridExtra)
library(RColorBrewer)
library(scales)
library(grid)
```

Loading the datasets:

```{r}
#loading datasets
df1 <- read_csv("global-temp-annual.csv")
df2 <- read_csv("owid-co2-data.csv")

```

Summary of dataset:

```{r}
#summary of datasets
cat("Dataset 1 Dimensions:", dim(df1), "\n")
cat("Dataset 2 Dimensions:", dim(df2), "\n")
cat(strrep("-", 50), "\n")
cat("Summary of Dataset 1: \n")
summary(df1)
cat(strrep("-", 50), "\n")
cat("Summary of Dataset 2: \n")
summary(df2)
cat(strrep("-", 50), "\n")
```

Examining Datasets:

```{r}

cat("Dataset 1 - First 6 rows:\n")
head(df1)
cat(strrep("-", 50), "\n")
cat("Dataset 2 - First 6 rows:\n")
head(df2)
cat(strrep("-", 50), "\n")

cat("Dataset 1 data types:\n")
sapply(df1, class)
cat(strrep("-", 50), "\n")
cat("Dataset 2 data types:\n")
sapply(df2, class)
cat(strrep("-", 50), "\n")

```

Checking for Missing Values:

```{r}
#analysing missing values
missing_df1 <- df1 %>%
  summarise_all(~sum(is.na(.))) %>%
  gather(key = "Variable", value = "Missing_Count") %>%
  mutate(
    Missing_Percentage = (Missing_Count / nrow(df1)) * 100,
    Present_Count = nrow(df1) - Missing_Count,
    Present_Percentage = 100 - Missing_Percentage
  ) %>%
  arrange(desc(Missing_Count))

print("Dataset 1 - Missing Values:")
print(missing_df1)

missing_df2 <- df2 %>%
  summarise_all(~sum(is.na(.))) %>%
  gather(key = "Variable", value = "Missing_Count") %>%
  mutate(
    Missing_Percentage = (Missing_Count / nrow(df2)) * 100,
    Present_Count = nrow(df2) - Missing_Count,
    Present_Percentage = 100 - Missing_Percentage
  ) %>%
  arrange(desc(Missing_Count))

print("Dataset 2 - Missing Values:")
print(missing_df2)

#visualising missing data patterns
p1 <- ggplot(missing_df1, aes(x = reorder(Variable, Missing_Percentage))) +
  geom_col(aes(y = Present_Percentage), fill = "#17becf", alpha = 0.8) +
  geom_col(aes(y = Missing_Percentage), fill = "#ff7f0e", alpha = 0.9) +
  coord_flip() +
  labs(
    title = "Missing Data Pattern - Dataset 1",
    subtitle = "Orange = Missing, Blue = Present",
    x = "Variables",
    y = "Percentage",
    caption = paste("Total observations:", nrow(df1))
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11, color = "gray60"),
    axis.text = element_text(size = 10),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  ) +
  scale_y_continuous(labels = function(x) paste0(x, "%"))

print(p1)


p2<- ggplot(missing_df2, aes(x = reorder(Variable, Missing_Percentage))) +
  geom_col(aes(y = Present_Percentage, text = paste("Variable:", Variable, "<br>Present:", round(Present_Percentage, 1), "%")), 
           fill = "#17becf", alpha = 0.8) +
  geom_col(aes(y = Missing_Percentage, text = paste("Variable:", Variable, "<br>Missing:", round(Missing_Percentage, 1), "%")), 
           fill = "#ff7f0e", alpha = 0.9) +
  coord_flip() +
  labs(title = "Missing Data Pattern - Dataset 2",
       x = "Variables", y = "Percentage") +
  theme_minimal() +
  theme(axis.text.y = element_blank())
ggplotly(p2, tooltip = "text")

```

Identifying duplicates and unique values in Data:

```{r}
cat("Dataset 1 duplicates:", sum(duplicated(df1)), "\n")
cat("Dataset 2 duplicates:", sum(duplicated(df2)), "\n")
cat(strrep("-", 50), "\n")

check_categorical <- function(df, dataset_name) {
  char_cols <- sapply(df, function(x) is.character(x) | is.factor(x))
  char_col_names <- names(df)[char_cols]
  
  for (col in char_col_names) {
    unique_count <- length(unique(df[[col]]))
    cat(sprintf("%s - %s: %d unique values\n", dataset_name, col, unique_count))
    
    if (unique_count <= 20) {
      print(table(df[[col]], useNA = "ifany"))
      cat("\n")
    }
  }
}

check_categorical(df1, "Dataset 1")
check_categorical(df2, "Dataset 2")
cat(strrep("-", 50), "\n")

```

Handling Missing Values:

```{r}
handle_missing_values <- function(df, strategy = "auto") {
  df_clean <- df

  missing_pct <- df %>%
    summarise_all(~sum(is.na(.)) / length(.) * 100)
  
  #remove columns with >50% missing values
  high_missing_cols <- names(missing_pct)[missing_pct > 50]
  if (length(high_missing_cols) > 0) {
    cat("Removing columns with >50% missing values:", paste(high_missing_cols, collapse = ", "), "\n")
    df_clean <- df_clean %>% select(-all_of(high_missing_cols))
  }
  cat(strrep("-", 60), "\n")
  retained_cols <- names(df_clean)
  cat("Retained", length(retained_cols), "columns:", paste(retained_cols, collapse = ", "), "\n")
  
  #handling remaining missing values
  for (col in names(df_clean)) {
    if (sum(is.na(df_clean[[col]])) > 0) {
      if (is.numeric(df_clean[[col]])) {
        #using median for numeric columns
        df_clean[[col]][is.na(df_clean[[col]])] <- median(df_clean[[col]], na.rm = TRUE)
      } else {
        #using mode for categorical columns
        mode_val <- names(sort(table(df_clean[[col]]), decreasing = TRUE))[1]
        df_clean[[col]][is.na(df_clean[[col]])] <- mode_val
      }
    }
  }
  
  return(df_clean)
}

df1_clean <- handle_missing_values(df1)
cat(strrep("-", 60), "\n")
cat("Dataset 1: Columns", ncol(df1), "->", ncol(df1_clean), "| Rows", nrow(df1), "->", nrow(df1_clean), "after cleaning\n")
cat(strrep("-", 60), "\n")

df2_clean <- handle_missing_values(df2)
cat(strrep("-", 60), "\n")
cat("Dataset 2: Columns", ncol(df2), "->", ncol(df2_clean), "| Rows", nrow(df2), "->", nrow(df2_clean), "after cleaning\n")
cat(strrep("-", 60), "\n")

#saving cleaned datasets
write.csv(df1_clean, "global-temp-annual-cleaned.csv", row.names = FALSE)
write.csv(df2_clean, "owid-co2-data-cleaned.csv", row.names = FALSE)

```

Univariate Analysis:

For numeric columns, we will use shapiro.test() to test if the data follows normal distribution.
Upon calculating the p-value:

- If p > 0.05: Data is likely normally distributed
- If p â‰¤ 0.05: Data significantly deviates from normal distribution

```{r}
create_univariate_plots <- function(df, dataset_name) {
  numeric_cols <- names(df)[sapply(df, is.numeric)]
  categorical_cols <- names(df)[sapply(df, is.factor)]

  for (col in numeric_cols) {
    p1 <- ggplot(df, aes(x = .data[[col]])) +
      geom_histogram(bins = 30, fill = "lightblue", alpha = 0.7) +
      ggtitle(paste("Distribution of", col)) +
      theme_minimal()
    
    p2 <- ggplot(df, aes(y = .data[[col]])) +
      geom_boxplot(fill = "lightgreen", alpha = 0.7) +
      ggtitle(paste("Boxplot of", col)) +
      theme_minimal()

    print(p1)
    print(p2)

    shapiro_test <- shapiro.test(sample(df[[col]], min(5000, length(df[[col]]))))
    cat(sprintf("%s - Shapiro-Wilk normality test p-value: %.6f\n", col, shapiro_test$p.value))
  }

  for (col in categorical_cols) {
    p <- ggplot(df, aes(x = .data[[col]])) +
      geom_bar(fill = "coral", alpha = 0.7) +
      ggtitle(paste("Distribution of", col)) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
    print(p)
  }
}

create_univariate_plots(df1_clean, "Dataset 1")
create_univariate_plots(df2_clean, "Dataset 2")
```

Correlation analysis between numeric variables in a dataset:

```{r}
analyze_correlations <- function(df, dataset_name) {
  numeric_df <- df[, sapply(df, is.numeric), drop = FALSE]
  
  if (ncol(numeric_df) < 2) {
    cat("Not enough numeric variables for correlation analysis in", dataset_name, "\n")
    return()
  }
  
  cor_matrix <- cor(numeric_df, use = "complete.obs")
  cat("=== CORRELATION MATRIX FOR", dataset_name, "===\n")
  print(round(cor_matrix, 3))
  corrplot(cor_matrix, method = "color", type = "upper", 
           order = "hclust", tl.cex = 0.8, tl.col = "black",
           title = paste("Correlation Matrix -", dataset_name))

  ggcorrplot::ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower",
                        lab = TRUE, lab_size = 3, method = "circle",
                        colors = c("red", "white", "blue"),
                        title = paste("Correlation Heatmap -", dataset_name))

  strong_correlations <- which(abs(cor_matrix) > 0.7 & cor_matrix != 1, arr.ind = TRUE)
  
  if (nrow(strong_correlations) > 0) {
    cat("\nStrong correlations (|r| > 0.7) in", dataset_name, ":\n")
    for (i in 1:nrow(strong_correlations)) {
      row_idx <- strong_correlations[i, 1]
      col_idx <- strong_correlations[i, 2]
      var1 <- rownames(cor_matrix)[row_idx]
      var2 <- colnames(cor_matrix)[col_idx]
      correlation <- cor_matrix[row_idx, col_idx]
      cat(sprintf("%s - %s: %.3f\n", var1, var2, correlation))

      p <- ggplot(df, aes(x = !!sym(var1), y = !!sym(var2))) +
        geom_point(alpha = 0.6, color = "blue") +
        geom_smooth(method = "lm", color = "red", se = TRUE) +
        ggtitle(paste(var1, "vs", var2, sprintf("(r = %.3f)", correlation))) +
        theme_minimal()
      print(p)
    }
  }
  
  return(cor_matrix)
}

cor_matrix1 <- analyze_correlations(df1_clean, "Dataset 1")
cor_matrix2 <- analyze_correlations(df2_clean, "Dataset 2")
```

Cross Dataset Analysis - Correlation Matrix for investigating how global temperatures are affected by CO2 levels:

```{r}
#preparing temperature data
temp_data <- df1_clean %>%
  select(Year, `Land and Ocean`) %>%
  rename(year = Year, global_temp = `Land and Ocean`) %>%
  filter(!is.na(global_temp))

#preparing CO2 data - aggregate global totals by year
co2_data <- df2_clean %>%
  group_by(year) %>%
  summarise(
    global_co2 = sum(co2, na.rm = TRUE),
    global_co2_per_capita = mean(co2_per_capita, na.rm = TRUE),
    global_cumulative_co2 = sum(cumulative_co2, na.rm = TRUE),
    global_ghg = sum(total_ghg, na.rm = TRUE),
    global_methane = sum(methane, na.rm = TRUE),
    global_nitrous_oxide = sum(nitrous_oxide, na.rm = TRUE),
    avg_temp_change_from_co2 = mean(temperature_change_from_co2, na.rm = TRUE),
    avg_temp_change_from_ghg = mean(temperature_change_from_ghg, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  filter(!is.na(global_co2) & global_co2 > 0)

combined_data <- inner_join(temp_data, co2_data, by = "year")

print(paste("Combined dataset has", nrow(combined_data), "years of data"))
print(paste("Year range:", min(combined_data$year), "-", max(combined_data$year)))
```

```{r}
#calculating correlations
correlation_vars <- combined_data %>%
  select(global_temp, global_co2, global_co2_per_capita, global_cumulative_co2, 
         global_ghg, global_methane, global_nitrous_oxide)

cor_matrix <- cor(correlation_vars, use = "complete.obs")
col <- colorRampPalette(brewer.pal(9, "Blues"))(200)
corrplot(cor_matrix, method = "color", col = col,
  addCoef.col = "white", tl.col = "black", tl.srt = 45, 
  title = "Temperature vs CO2 Correlations", 
  mar = c(0,0,3,0), number.cex = 0.8, cl.cex = 0.8, tl.cex = 0.9, 
  outline = TRUE, addgrid.col = NA)
```

Cross Dataset Analysis - Time Series Analysis for investigating how global temperatures are affected by CO2 levels:

```{r, fig.width=10, fig.height=6, dev='png'}
combined_data_norm <- combined_data %>% 
  mutate(
    temp_norm = scale(global_temp)[,1],
    co2_norm = scale(global_co2)[,1], 
    cumulative_co2_norm = scale(global_cumulative_co2)[,1]
  )

#interactive time series plot
p1 <- plot_ly(combined_data_norm, x = ~year) %>%
  add_lines(y = ~temp_norm, 
            name = "Global Temperature", 
            line = list(color = "#1f77b4", width = 3),
            hovertemplate = "<b>Global Temperature</b><br>Year: %{x}<br>Z-score: %{y:.3f}<br><extra></extra>") %>%
  add_lines(y = ~co2_norm, 
            name = "Annual CO2", 
            line = list(color = "#ff7f0e", width = 3),
            hovertemplate = "<b>Annual CO2</b><br>Year: %{x}<br>Z-score: %{y:.3f}<br><extra></extra>") %>%
  add_lines(y = ~cumulative_co2_norm, 
            name = "Cumulative CO2", 
            line = list(color = "#2ca02c", width = 3),
            hovertemplate = "<b>Cumulative CO2</b><br>Year: %{x}<br>Z-score: %{y:.3f}<br><extra></extra>") %>%
  layout(
    title = list(text = "Normalized Trends: Temperature vs CO2 (1960-2020)", 
                 font = list(size = 16)),
    xaxis = list(title = "Year"),
    yaxis = list(title = "Normalized Values (Z-scores)"),
    legend = list(x = 0, y = -0.15, orientation = "h"),
    hovermode = "x unified",
    plot_bgcolor = "white",
    paper_bgcolor = "white"
  ) %>%
  config(displayModeBar = TRUE, 
         modeBarButtonsToRemove = c("pan2d", "select2d", "lasso2d", "autoScale2d"))

p1
```

Scatter Plot Analysis:

```{r}
p2 <- ggplot(combined_data, aes(x = global_co2, y = global_temp)) + 
  geom_point(aes(color = year), size = 3, alpha = 0.8) + 
  geom_smooth(method = "lm", se = TRUE, color = "red", size = 1.2, alpha = 0.3) + 
  scale_color_gradient(low = "darkblue", high = "lightblue", 
                       name = "Year",
                       breaks = seq(1880, 2020, 20),
                       labels = seq(1880, 2020, 20)) +
  scale_x_continuous(labels = function(x) format(x, big.mark = ",", scientific = FALSE)) +
  labs(title = "Global Temperature vs Annual CO2 Emissions",
       x = "Global CO2 Emissions (Million Tonnes)", 
       y = "Global Temperature Anomaly (Â°C)") + 
  theme_minimal() +
  theme(
    plot.title = element_text(size = 9, face = "bold", hjust = 0.5, margin = margin(b = 20)),
    axis.title = element_text(size = 7, face = "bold"),
    axis.text = element_text(size = 6),
    legend.title = element_text(size = 7, face = "bold"),
    legend.text = element_text(size = 7),
    legend.position = "right",
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "gray80", fill = NA, size = 0.5),
    plot.margin = margin(t = 20, r = 10, b = 20, l = 10)
  )

p3 <- ggplot(combined_data, aes(x = global_cumulative_co2, y = global_temp)) + 
  geom_point(aes(color = year), size = 3, alpha = 0.8) + 
  geom_smooth(method = "lm", se = TRUE, color = "red", size = 1.2, alpha = 0.3) + 
  scale_color_gradient(low = "darkblue", high = "lightblue", 
                       name = "Year",
                       breaks = seq(1880, 2020, 20),
                       labels = seq(1880, 2020, 20)) +
  scale_x_continuous(labels = function(x) paste0(round(x/1000, 1), "B")) +
  labs(title = "Global Temperature vs Cumulative CO2 Emissions",
       x = "Cumulative CO2 Emissions (Billion Tonnes)", 
       y = "Global Temperature Anomaly (Â°C)") + 
  theme_minimal() +
  theme(
    plot.title = element_text(size = 9, face = "bold", hjust = 0.5, margin = margin(b = 20)),
    axis.title = element_text(size = 7, face = "bold"),
    axis.text = element_text(size = 6),
    legend.title = element_text(size = 7, face = "bold"),
    legend.text = element_text(size = 7),
    legend.position = "right",
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "gray80", fill = NA, size = 0.5),
    plot.margin = margin(t = 20, r = 10, b = 20, l = 10)
  )

combined_plot <- grid.arrange(p2, p3, ncol = 2)

print(combined_plot)
```
Simple Linear Regression Analysis:

The model summaries show the following for each model

- Coefficients: how much temperature changes per unit of each gas
- R-squared: how much of temperature variation the model explains
- P-values: statistical significance
- Residual standard error: model accuracy

The model comparision table shows the following

- R-squared: Percentage of temperature variation explained (higher = better)
- Adjusted R-squared: R-squared adjusted for number of variables (accounts for model complexity)
- AIC (Akaike Information Criterion): Model quality measure (lower = better, balances fit vs complexity)

```{r}
model1 <- lm(global_temp ~ global_co2, data = combined_data)
model2 <- lm(global_temp ~ global_cumulative_co2, data = combined_data)
model3 <- lm(global_temp ~ global_co2 + global_methane + global_nitrous_oxide, 
             data = combined_data)

cat("\n=== MODEL 1: Temperature ~ Annual CO2 ===\n")
print(summary(model1))

cat("\n=== MODEL 2: Temperature ~ Cumulative CO2 ===\n")
print(summary(model2))

cat("\n=== MODEL 3: Temperature ~ Multiple GHGs ===\n")
print(summary(model3))

models_comparison <- data.frame(
  Model = c("Annual CO2", "Cumulative CO2", "Multiple GHGs"),
  R_squared = c(summary(model1)$r.squared, 
                summary(model2)$r.squared, 
                summary(model3)$r.squared),
  Adjusted_R_squared = c(summary(model1)$adj.r.squared,
                        summary(model2)$adj.r.squared,
                        summary(model3)$adj.r.squared),
  AIC = c(AIC(model1), AIC(model2), AIC(model3))
)

print("Model Comparison:")
print(models_comparison)
```

Lag Analysis:

Tests whether past emissions are better predictors than current emissions.

- From the output of the below code, we see that the climate system does have inertia and the CO2 emissions from previous years can affect the current year temperature.

```{r}
combined_data_lag <- combined_data %>%
  arrange(year) %>%
  mutate(
    co2_lag1 = lag(global_co2, 1),
    co2_lag2 = lag(global_co2, 2),
    co2_lag5 = lag(global_co2, 5),
    temp_change = global_temp - lag(global_temp, 1)
  )

lag_correlations <- combined_data_lag %>%
  select(global_temp, global_co2, co2_lag1, co2_lag2, co2_lag5) %>%
  cor(use = "complete.obs")

print("Lag Correlations (Temperature with CO2):")
print(round(lag_correlations[1, ], 3))
```

Change Rate Analysis:

The output below shows a negative correlation between temperature growth rate and CO2 growth rate.
The negative correlation suggests that year-to-year emission fluctuations don't directly translate to immediate temperature responses. This is consistent with the lag analysis and climate science studies that:

- Long-term cumulative CO2 emissions are more influential on temperature trends than short-term annual changes.
- Averaging data over multiple years is more likely to reveal the expected positive relationship between emissions and temperature.
- Due to the inertia of the climate system, current temperatures largely reflect the integrated effect of past emissions rather than short-term fluctuations.

```{r}
combined_data_rates <- combined_data %>%
  arrange(year) %>%
  mutate(
    temp_rate = (global_temp - lag(global_temp, 1)) / 1,
    co2_rate = (global_co2 - lag(global_co2, 1)) / lag(global_co2, 1) * 100
  ) %>%
  filter(!is.na(temp_rate) & !is.na(co2_rate))

rate_correlation <- cor(combined_data_rates$temp_rate, 
                       combined_data_rates$co2_rate, use = "complete.obs")

cat(paste("\nCorrelation between temperature change rate and CO2 growth rate:", 
          round(rate_correlation, 3)))

p4 <- ggplot(combined_data_rates, aes(x = co2_rate, y = temp_rate)) +
  geom_point(aes(color = year), size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE) +
  labs(title = "Temperature Change Rate vs CO2 Growth Rate",
       x = "CO2 Growth Rate (%)",
       y = "Temperature Change Rate (Â°C/year)",
       color = "Year") +
  theme_minimal()

print(p4)
```

Interactive Plots:

```{r,  fig.width=10, fig.height=6, dev='png'}
interactive_plot <- plot_ly(combined_data, x = ~year, y = ~global_temp, 
                           type = 'scatter', mode = 'lines+markers',
                           name = 'Temperature', yaxis = 'y') %>%
  add_trace(y = ~global_co2/1000, name = 'CO2 (Thousands)', yaxis = 'y2') %>%
  layout(
    title = "Global Temperature vs CO2 Over Time",
    xaxis = list(title = "Year"),
    yaxis = list(title = "Temperature Anomaly (Â°C)"),
    yaxis2 = list(side = 'right', overlaying = 'y', 
                  title = 'CO2 Emissions (Thousand Million Tonnes)')
  )

interactive_plot
```

Summary:

```{r}
cat("\n=== SUMMARY FINDINGS ===\n")
cat(paste("Data covers", nrow(combined_data), "years from", 
          min(combined_data$year), "to", max(combined_data$year), "\n"))
cat(paste("Temperature-CO2 correlation:", 
          round(cor(combined_data$global_temp, combined_data$global_co2), 3), "\n"))
cat(paste("Temperature-Cumulative CO2 correlation:", 
          round(cor(combined_data$global_temp, combined_data$global_cumulative_co2), 3), "\n"))
cat(paste("Best model R-squared:", 
          round(max(models_comparison$R_squared), 3), "\n"))
```

